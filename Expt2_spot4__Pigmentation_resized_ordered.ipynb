{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expt2_spot4_ Pigmentation_resized_ordered.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoelleI/Pigmentation/blob/master/Expt2_spot4__Pigmentation_resized_ordered.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "241BvQNpfNyB",
        "colab_type": "text"
      },
      "source": [
        "# Melanoma with CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPubA4t4fNyC",
        "colab_type": "text"
      },
      "source": [
        "This analysis trains a neural network to perform segmentation on melanoma data and then applies the algorithm to segment a pigmentation lesion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0VaxmP22GVM",
        "colab_type": "text"
      },
      "source": [
        "This line clones the github repository so that data may be accessed and the file can be saved there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSl392jIi_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NoelleI/Pigmentation.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cswYjth4ck7",
        "colab_type": "text"
      },
      "source": [
        "This mounts Google Drive to access the ~10G melanoma photo data sets\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ReR4v01td3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efKvkEMKfNyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "%matplotlib inline\n",
        "# First, load the image\n",
        "#dir_path = os.path.dirname(os.path.realpath(__file__))\n",
        "filename = \"./Pigmentation/pigmentation.png\"\n",
        "\n",
        "# Load the image\n",
        "pigment_image = mpimg.imread(filename)\n",
        "\n",
        "# Print out its shape\n",
        "print(pigment_image.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0fuEbnzfNyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r-Pb0MCfNyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(pigment_image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRiNFY6gfNyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigment_image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ccZ5owfNyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage\n",
        "pigment_image_resized = skimage.transform.resize(pigment_image, (192,256,3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqpbxiAQfNyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##note: in order to discern the melanin content, it will be necessary to understand how this resizing algorithm works: does it take a maximum value? What does it use?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDWN9Rp5fNyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(pigment_image_resized)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8c0wI8hfNyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(pigment_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gV5JVt3fNya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "pigment_image_show = pigment_image_resized\n",
        "pigment_image_resized = np.reshape(pigment_image_resized, [1,192,256,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ48pRh55Xv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "scipy.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XHIF5mdmW1X",
        "colab": {}
      },
      "source": [
        "!pip install pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tBqV9RTtmYOX",
        "colab": {}
      },
      "source": [
        "if not (scipy.__version__ == '1.0.0'):\n",
        "  !pip uninstall scipy==1.3.0\n",
        "  !pip install scipy==1.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLb2SmFqfNyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import ndimage, misc\n",
        "import re\n",
        "import os\n",
        "#get pigmentation photos\n",
        "pigs = []\n",
        "filenames_dict = {}\n",
        "#for root, dirnames, filenames in os.walk(\"./Pigmentation/Pigmentation_photos/Experiment 2/Spot 1\"): \n",
        "    #for filename in filenames:\n",
        "        #if re.search('d*.PNG', filename):\n",
        "            #filepath = os.path.join(root, filename)\n",
        "            #pig = ndimage.imread(filepath)\n",
        "            #pig_resized = skimage.transform.resize(pig, (192,256,3))  #redo this size or re-size later in Tensorflow\n",
        "            #pigs.append(pig_resized)\n",
        "            #filename = filename.split(\".\")\n",
        "            #name = filename[0] + \"2.\" + filename[1]\n",
        "            #print(name)\n",
        "            \n",
        "            #new_path = os.path.join(root, name)\n",
        "            #f = open(new_path, 'w+b')\n",
        "            #misc.imsave(new_path, _seg_resized)\n",
        "            #os.remove(filepath)\n",
        "            #f.close()\n",
        "#pigs = np.array(pigs)\n",
        "\n",
        "for root, dirnames, filenames in os.walk(\"./Pigmentation/Pigmentation_photos/Experiment 1/Spot 4\"): #/content/gdrive/My Drive/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input\"):\n",
        "    #print(filenames)\n",
        "    for filename in filenames:\n",
        "            #print(filename, \"\\n\")\n",
        "      #if re.search('d*[^{r|f}].jpg', filename):\n",
        "            n = re.match(\"(\\d*)\", filename)\n",
        "            #print(n.group(), \" \")\n",
        "            #print(filename, \"\\n\")\n",
        "            #print(os.path.join(root, filename), \"\\n\")\n",
        "            filenames_dict.update({int(n.group()): os.path.join(root, filename)})\n",
        "            #print(filenames_dict, \"\\n\\n\")\n",
        "#print(filenames_dict.keys(),\"\\n\")\n",
        "for key in sorted(filenames_dict.keys()):\n",
        "  #print(key,filenames_dict[key], \"\\n\")\n",
        "  image = ndimage.imread(filenames_dict[key], mode=\"RGB\")\n",
        "  image = skimage.transform.resize(image, (192,256,3))  #redo this size or re-size later in Tensorflow\n",
        "  \n",
        "  pigs+= [image]\n",
        "  \n",
        "  \n",
        "pigs = np.array(pigs)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITY3B3BQQpIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigs = np.asarray(pigs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw0kvHibfNyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## I created a train-test split in the original upload of files to Google Docs, but I will merge these because I've realized that I can still use train-test split below and it will \n",
        "## randomize the photos each time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mU8NkH8Qnzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xobg6n-hQlvf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZK6LNtK22F0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from skimage import data\n",
        "from skimage.color import rgb2hsv, rgb2lab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBO_amNV41oG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import ndimage, misc\n",
        "import re\n",
        "import os\n",
        "#there are 2594 photos\n",
        "filenames_dict = {}\n",
        "for root, dirnames, filenames in os.walk(\"/content/gdrive/My Drive/Batches/ISIC2018_Task1-2_Training_Input_batches\"): #/content/gdrive/My Drive/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input\"):\n",
        "    for filename in filenames:\n",
        "      if re.search('d*[^{r|f}].jpg', filename):\n",
        "            n = re.match(\"ISIC_(\\d*).\", filename)\n",
        "            filenames_dict.update({n.group(1): os.path.join(root, filename)})\n",
        "           \n",
        "           \n",
        "for root, dirnames, filenames in os.walk(\"/content/gdrive/My Drive/Batches/ISIC2018_Task1-2_Testing_Input_batches\"): #/content/gdrive/My Drive/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input\"):\n",
        "    for filename in filenames:\n",
        "      if re.search('d*[^{r|f}].jpg', filename):\n",
        "            n = re.match(\"ISIC_(\\d*).\", filename)\n",
        "            filenames_dict.update({n.group(1): os.path.join(root, filename)})\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dtBAhE379SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"/content/gdrive/My Drive/Batches/ISIC2018_Task1_Training_GroundTruth_batches\"\n",
        "\n",
        "from scipy import ndimage, misc\n",
        "import re\n",
        "import os\n",
        "#there are 2594 photos\n",
        "labelnames_dict = {}\n",
        "for root, dirnames, filenames in os.walk(\"/content/gdrive/My Drive/Batches/ISIC2018_Task1_Training_GroundTruth_batches\"): #/content/gdrive/My Drive/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input\"):\n",
        "    for filename in filenames:\n",
        "      if re.search('d*[^{r|f}]_segmentation.png', filename):\n",
        "           \n",
        "            n = re.match(\"ISIC_(\\d*)_\\w+\", filename)\n",
        "            labelnames_dict.update({n.group(1): os.path.join(root, filename)})\n",
        "           \n",
        "for root, dirnames, filenames in os.walk(\"/content/gdrive/My Drive/Batches/ISIC2018_Task1_Testing_GroundTruth_batches\"): #/content/gdrive/My Drive/ISIC2018_Task1-2_Training_Input/ISIC2018_Task1-2_Training_Input\"):\n",
        "    for filename in filenames:\n",
        "      if re.search('d*[^{r|f}]_segmentation.png', filename):\n",
        "            n = re.match(\"ISIC_(\\d*)_\\w+\", filename)\n",
        "            labelnames_dict.update({n.group(1): os.path.join(root, filename)})\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thW4Wug6BTem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = []\n",
        "segs = []\n",
        "for key in sorted(labelnames_dict.keys()):\n",
        "  image = ndimage.imread(filenames_dict[key], mode=\"RGB\")\n",
        "  seg = ndimage.imread(labelnames_dict[key], mode=\"L\")\n",
        "  images += [image]\n",
        "  segs += [seg]\n",
        "  \n",
        "images = np.array(images)\n",
        "segs = np.array(segs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbcJxgPhDqfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDyIgJ4sDw54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(segs[10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iuI-mZ_D5iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(images[10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHX6zN6QfNyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = images[2580,:,:,:]/255\n",
        "print(image)\n",
        "rotate_image = ndimage.rotate(image, 45)\n",
        "#rotate_image = misc.imresize(rotate_image, (192,256,6))\n",
        "print(rotate_image)\n",
        "plt.imshow(rotate_image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXWnSaquyMWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65gwtHvIyPKN",
        "colab_type": "text"
      },
      "source": [
        "***The images look blurry***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "L4oVdioPfNyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = images[0,:,:,:]\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8N4Xlk9fNzN",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS6Tms7_fNzN",
        "colab_type": "text"
      },
      "source": [
        "Function to help intialize random weights for fully connected or convolutional layers, we leave the shape attribute as a parameter for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwxTUCjRfNzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainim, testim, trainlab, testlab = train_test_split(images, segs, test_size = 0.05) #this is randomized each time the program is started and run from scratch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIxY01G3fNzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainim.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-zXpjhkfNzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.max(testlab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndDyqlFhfNzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testlab.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C4pwHf7fNza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = trainlab[0,:,:]\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EiH3SAJc3Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = trainim[0,:,:,:]\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUklfcm1SSVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_augmentations(features,lables,flag):\n",
        "  if flag:\n",
        "    #print(\"treat the first input image\")\n",
        "    #hsv_img = rgb2hsv(features[0])  #add 3 hsv channels       \n",
        "    #plt.imshow(features[0])\n",
        "    #plt.show()\n",
        "    #plt.imshow(hsv_img)\n",
        "    #plt.show()\n",
        "    #print(hsv_img.dtype)\n",
        "    #print(features[0].dtype)\n",
        "    #print(hsv_img)\n",
        "    #print(features[0])\n",
        "    #l = rgb2lab(features[0])[:,:,0].reshape(192,256,1) #add the l channel from the lab space\n",
        "    #image = np.concatenate((features[0]/255,hsv_img,l), axis =2)  #concatenate into one big image\n",
        "    x2 = features[0].reshape([1,192,256,3]) #image.reshape([1,192,256,7])  #need to add \"1\" to first dimension for future concatenation\n",
        "    image = features[0]\n",
        "    #print(\"#flip the first image:\")\n",
        "    flip_ud_x2 = np.flipud(image).reshape([1,192,256,3])\n",
        "    #plt.imshow(flip_ud_x2[0,:,:,:3])\n",
        "   \n",
        "    #plt.show()\n",
        "    x2 = np.vstack((x2, flip_ud_x2)) \n",
        "    \n",
        "    #print(\"#rotate the first image by a random angle\")\n",
        "    ra = np.random.random()*360\n",
        "    rotate_x2 = ndimage.rotate(image, ra)\n",
        "    #print(image)\n",
        "    #print(rotate_x2)\n",
        "    #plt.imshow(rotate_x2[:,:,:3])\n",
        "    #plt.show()\n",
        "    #print(\"test1\")\n",
        "    rotate_x2 = skimage.transform.resize(rotate_x2, (1,192,256,3))\n",
        "    #plt.imshow(rotate_x2[0,:,:,:3])\n",
        "    #print(\"test2\")\n",
        "    x2 = np.vstack((x2, rotate_x2 )) \n",
        "    \n",
        "    #print(\"#treat the first label:\")\n",
        "    label = lables[0]\n",
        "    #plt.imshow(label)\n",
        "    #plt.show()\n",
        "    y2 = label.reshape([1,192,256,1])\n",
        "    #print(\"#flip the first label to match the first input image:\")\n",
        "    flip_ud_y2 = np.flipud(label).reshape([1,192,256,1])\n",
        "    y2 = np.vstack((y2, flip_ud_y2)) \n",
        "    #plt.imshow(flip_ud_y2[0:,:,:,:])\n",
        "    #plt.show()\n",
        "    #print(\"#rotate the label by the same angle as the image\")\n",
        "    rotate_y2 = ndimage.rotate(label, ra)\n",
        "    rotate_y2 = skimage.transform.resize(rotate_y2, (1,192,256,1))\n",
        "    y2 = np.vstack((y2, rotate_y2)) \n",
        "    #plt.imshow(rotate_y2) \n",
        "    #plt.show()\n",
        "  \n",
        "    i = 1\n",
        "    \n",
        "    #print('#treat the subsequent images and labels')\n",
        "    for image in features[1:]:\n",
        "      #print(i)\n",
        "      #plt.imshow(image)\n",
        "      #plt.show()\n",
        "      #hsv_img = rgb2hsv(image)  #add 3 hsv channels       \n",
        "      #plt.imshow(hsv_img)\n",
        "      #plt.show()\n",
        "      #l = rgb2lab(image)[:,:,0].reshape(192,256,1) #add the l channel from the lab space\n",
        "      #image = np.concatenate((image,hsv_img,l), axis =2)  #concatenate into one big image\n",
        "      image2 = image.reshape([1,192,256,3])  #need to add \"1\" to first dimension for future concatenation\n",
        "      \n",
        "      x2 = np.vstack((x2, image2))\n",
        "      #print('#flip the image:')\n",
        "      flip_ud_x2 = np.flipud(image).reshape([1,192,256,3])\n",
        "      x2 = np.vstack((x2, flip_ud_x2))\n",
        "      #plt.imshow(flip_ud_x2[1,:,:,:3])\n",
        "      #plt.show()\n",
        "     \n",
        "      #print('#rotate the image by a random angle')\n",
        "      ra = np.random.random()*360\n",
        "      rotate_x2 = ndimage.rotate(image, ra)\n",
        "      rotate_x2 = skimage.transform.resize(rotate_x2, (1,192,256,3))\n",
        "      x2 = np.vstack((x2, rotate_x2))\n",
        "      #plt.imshow(rotate_x2[0,:,:,:3])\n",
        "      #plt.show()\n",
        "      \n",
        "     \n",
        "      #print('#treat the corresponding label:')\n",
        "      label = lables[i]\n",
        "      label2 = lables[i].reshape([1,192,256,1])\n",
        "      #plt.imshow(label)\n",
        "      #plt.show()\n",
        "     \n",
        "      y2 = np.vstack((y2,label2))\n",
        "      #print('#flip the corresponding label to match the input image:')\n",
        "      flip_ud_y2 = np.flipud(label).reshape([1,192,256,1])\n",
        "      y2 = np.vstack((y2,flip_ud_y2))\n",
        "      #plt.imshow(flip_ud_y2[0,:,:,:])\n",
        "      #plt.show()\n",
        "      \n",
        "      \n",
        "      #print('#rotate the label by the same angle as the image')\n",
        "      rotate_y2 = ndimage.rotate(label, ra)\n",
        "      rotate_y2 = skimage.transform.resize(rotate_y2, (1,192,256,1))\n",
        "      y2 = np.vstack((y2,rotate_y2))\n",
        "      #plt.imshow(rotate_y2) \n",
        "      #plt.show()\n",
        "      \n",
        "      #print('#scale images to 0-1 interval')\n",
        "    x2 = x2/255\n",
        "    y2 = y2/255\n",
        "  else:\n",
        "     x2 = features/255\n",
        "     y2 = lables/255\n",
        "  return x2, y2\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj7akIWSM2YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MelHelper():\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.i = 0\n",
        "        \n",
        "        ####Can probably eliminate this part ####\n",
        "        \n",
        "        # Grabs a list of all the data batches for training\n",
        "        #self.all_train_batches = [data_batch1,data_batch2,data_batch3,data_batch4,data_batch5]\n",
        "        # Grabs a list of all the test batches (really just one batch)\n",
        "        #self.test_batch = [test_batch]\n",
        "        \n",
        "        ###eliminate####\n",
        "        \n",
        "        # Intialize some empty variables for later on\n",
        "        self.training_images = None\n",
        "        self.training_labels = None\n",
        "        \n",
        "        self.test_images = None\n",
        "        self.test_labels = None\n",
        "    \n",
        "    def set_up_images(self):\n",
        "        \n",
        "        print(\"Setting Up Training Images and Labels\")\n",
        "       \n",
        "        self.training_images = trainim   #normalize only ->replace with images with training set later\n",
        "                                #self.training_images.reshape(train_len,3,32,32).transpose(0,2,3,1)/255\n",
        "       \n",
        "        self.training_labels = np.around(trainlab) #one_hot_encode(np.hstack([d[b\"labels\"] for d in self.all_train_batches]), 10)\n",
        "        \n",
        "        print(\"Setting Up Test Images and Labels\")\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "      \n",
        "        self.test_images, labls = data_augmentations(testim, testlab,0)\n",
        "        self.test_labels = labls.reshape((labls.shape[0],192,256))\n",
        "       \n",
        "        \n",
        "    def next_batch(self, batch_size):\n",
        "        # Note that the 100 dimension in the reshape call is set by an assumed batch size of 100 - this is now a mistake\n",
        "        xtra = (self.i + batch_size) % len(self.training_images)\n",
        "        if xtra<batch_size and xtra != 0:\n",
        "            x = np.vstack((self.training_images[self.i:self.i+batch_size], self.training_images[0:xtra])) #.reshape(100,32,32,3)  #why is this necessary?\n",
        "            y = np.vstack((self.training_labels[self.i:self.i+batch_size], self.training_labels[0:xtra]))\n",
        "        else:\n",
        "            x = self.training_images[self.i:self.i+batch_size] #.reshape(100,32,32,3)  #why is this necessary?\n",
        "            y = self.training_labels[self.i:self.i+batch_size]\n",
        "        #print(x.shape)\n",
        "        x,y = data_augmentations(x,y,0)\n",
        "        y = y.reshape((y.shape[0],192,256))\n",
        "        self.i = xtra \n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTmLVENAfNze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(shape):\n",
        "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(init_random_dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Yh6X2mfNzg",
        "colab_type": "text"
      },
      "source": [
        "Same as init_weights, but for the biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd3vlocsfNzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_bias(shape):\n",
        "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(init_bias_vals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyF20ufBfNzi",
        "colab_type": "text"
      },
      "source": [
        "Create a 2D convolution using builtin conv2d from TF. From those docs:\n",
        "\n",
        "Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
        "\n",
        "Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
        "and a filter / kernel tensor of shape\n",
        "`[filter_height, filter_width, in_channels, out_channels]`, this op\n",
        "performs the following:\n",
        "\n",
        "1. Flattens the filter to a 2-D matrix with shape\n",
        "   `[filter_height * filter_width * in_channels, output_channels]`.\n",
        "2. Extracts image patches from the input tensor to form a *virtual*\n",
        "   tensor of shape `[batch, out_height, out_width,\n",
        "   filter_height * filter_width * in_channels]`.\n",
        "3. For each patch, right-multiplies the filter matrix and the image patch\n",
        "   vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvrLH9wufNzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dofb-mrtfNzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deconv2d(x, shape):\n",
        "    return tf.layers.conv2d_transpose(x, shape[3], shape[0:2], padding = 'SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIO9pWjXfNzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_pool_2by2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], \n",
        "                          strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VqEnybqfNzs",
        "colab_type": "text"
      },
      "source": [
        "Using the conv2d function, we'll return an actual convolutional layer here that uses an ReLu activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS9b-naGfNzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_layer(input_x, shape):\n",
        "    if input_x.shape[0]==1:\n",
        "      training = False\n",
        "    else: training = True\n",
        "    W = init_weights(shape)\n",
        "    b = init_bias([shape[3]])\n",
        "    c = conv2d(input_x, W) + b   ###put batch normalization here because it should include the weights\n",
        "    bnc = tf.layers.batch_normalization(c, training = training)\n",
        "    return tf.nn.relu(bnc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0-cGJDsfNzu",
        "colab_type": "text"
      },
      "source": [
        "This is a normal fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9tiw8fKfNzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_full_layer(input_layer, size):\n",
        "    input_size = int(input_layer.get_shape()[1])\n",
        "    W = init_weights([input_size, size])\n",
        "    b = init_bias([size])\n",
        "    return tf.matmul(input_layer, W) + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoKldfkxfNzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deconvolutional_layer(input_x, shape):\n",
        "    #W = init_weights(shape)\n",
        "    if input_x.shape[0]==1:\n",
        "      training = False\n",
        "    else: training = True\n",
        "    b = init_bias([shape[3]])  #draw this out to see if it makes sense\n",
        "    d = deconv2d(input_x, shape) +b\n",
        "    bnd = tf.layers.batch_normalization(d, training = training)\n",
        "    return tf.nn.relu(bnd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I52QXtPPGU1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input_x, shape):\n",
        "    #W = init_weights(shape)\n",
        "    if input_x.shape[0]==1:\n",
        "      training = False\n",
        "    else: training = True\n",
        "    b = init_bias([shape[3]])  #draw this out to see if it makes sense\n",
        "    d = deconv2d(input_x, shape) +b\n",
        "    \n",
        "    return tf.nn.sigmoid(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38-BkLy-G_q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2rwibDxfNzz",
        "colab_type": "text"
      },
      "source": [
        "### Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E82SWUmfNz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32,shape=[None,192,256,images.shape[3]])  #trace the shaping of these through the code...\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2djuEyMfNz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "y_true = tf.placeholder(tf.float32,shape=[None,192,256])  #this now has every pixel in the ground truth segmentation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzopPGJyfNz5",
        "colab_type": "text"
      },
      "source": [
        "### Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YyKmti2fNz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_image = tf.reshape(x,[-1,192,256,images.shape[3]])  #-1 infers the shape of the first dimension (here, the batch size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2zOibybfNz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
        "# You can change the 32 output, that essentially represents the amount of filters used\n",
        "# You need to pass in 32 to the next input though, the 1 comes from the original input of \n",
        "# a single image.\n",
        "convo_1 = convolutional_layer(x_image,shape=[3,3,images.shape[3],16])\n",
        "convo_12 = convolutional_layer(convo_1,shape=[3,3,16,32])\n",
        "convo_1_pooling = max_pool_2by2(convo_12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3wMs2SYTVpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(convo_1_pooling.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjs326AsfNz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
        "# You can actually change the 64 output if you want, you can think of that as a representation\n",
        "# of the amount of 6by6 filters used.\n",
        "convo_2 = convolutional_layer(convo_1_pooling,shape=[3,3,32,64])\n",
        "convo_22 = convolutional_layer(convo_2,shape=[3,3,64,64])\n",
        "convo_2_pooling = max_pool_2by2(convo_22)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSeZobE1fNz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(convo_2_pooling.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0yF11JTfN0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
        "## You can actually change the 64 output if you want, you can think of that as a representation\n",
        "# of the amount of 6by6 filters used.\n",
        "convo_3 = convolutional_layer(convo_2_pooling,shape=[3,3,64,128])\n",
        "convo_32 = convolutional_layer(convo_3,shape=[3,3,128,128])\n",
        "convo_3_pooling = max_pool_2by2(convo_32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1OFvnKJfN0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(convo_3_pooling.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK5Ch1YKfN0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using a 6by6 filter here, used 5by5 in video, you can play around with the filter size\n",
        "# You can actually change the 64 output if you want, you can think of that as a representation\n",
        "# of the amount of 6by6 filters used.\n",
        "hold_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "convo_3_pooling_d = tf.nn.dropout(convo_3_pooling,keep_prob=hold_prob)\n",
        "\n",
        "\n",
        "convo_4 = convolutional_layer(convo_3_pooling_d,shape=[3,3,128,256])\n",
        "convo_42 = convolutional_layer(convo_4,shape=[3,3,256,256])\n",
        "convo_4_pooling = max_pool_2by2(convo_42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLw9sqc3fN0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(convo_4_pooling.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrjbYcoHfN0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convo_5 = convolutional_layer(convo_4_pooling,shape=[3,3,256,512])\n",
        "#convo_5_pooling = max_pool_2by2(convo_5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUhatLBVfN0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(convo_5.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2umt_QNxfN0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convo_6 = convolutional_layer(convo_5,shape=[3,3,128,256])\n",
        "#convo_6_pooling = max_pool_2by2(convo_6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1RQ1ZCcfN0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(convo_6.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymjgp2j1RCFe",
        "colab_type": "text"
      },
      "source": [
        "###Need to look at the shapes and sizes of all of these layers###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnPU1krEfN0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import keras\n",
        "deconv_1 = deconvolutional_layer(convo_5, shape = [3,3,512,256])\n",
        "H = deconv_1.shape[1]\n",
        "W = deconv_1.shape[2]\n",
        "ups_1 = tf.image.resize_nearest_neighbor(deconv_1, size = [2*H,2*W])\n",
        "print(ups_1.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tebp1_E5vDNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deconv_2 = deconvolutional_layer(ups_1, shape = [3,3,256,256])\n",
        "deconv_22 = deconvolutional_layer(deconv_2, shape = [3,3,256,128])\n",
        "H = deconv_22.shape[1]\n",
        "W = deconv_22.shape[2]\n",
        "ups_2 = tf.image.resize_nearest_neighbor(deconv_22, size = [2*H,2*W])\n",
        "print(ups_2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsq6Tw5_wCbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deconv_3 = deconvolutional_layer(ups_2, shape = [4,4,128,128])\n",
        "deconv_32 = deconvolutional_layer(deconv_3, shape = [3,3,128,128])\n",
        "H = deconv_32.shape[1]\n",
        "W = deconv_32.shape[2]\n",
        "ups_3 = tf.image.resize_nearest_neighbor(deconv_32, size = [2*H,2*W])\n",
        "print(ups_3.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk9mtSG50McP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deconv_4 = deconvolutional_layer(ups_3, shape = [3,3,128,64])\n",
        "deconv_42 = deconvolutional_layer(deconv_4, shape = [3,3,64,32])\n",
        "H = deconv_42.shape[1]\n",
        "W = deconv_42.shape[2]\n",
        "ups_4 = tf.image.resize_nearest_neighbor(deconv_42, size = [2*H,2*W])\n",
        "print(ups_4.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O07s0bzd-xdZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhVu8DWQ0unq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hold_prob2 = tf.placeholder(tf.float32)\n",
        "\n",
        "ups_4_d = tf.nn.dropout(ups_4,keep_prob=hold_prob2)\n",
        "\n",
        "deconv_5 = deconvolutional_layer(ups_4_d, shape = [3,3,32,16])\n",
        "print(deconv_5.shape)\n",
        "output = output_layer(deconv_5, shape = [3,3,16,1])\n",
        "#print(deconv_52.shape)\n",
        "#output = tf.image.resize_nearest_neighbor(deconv_52, size = [192,256])   #not sure what sort of output layer is used in the winning submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6WCdpU44eEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deconv_5.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk0vZ8CofN0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzfSiPBifN0i",
        "colab_type": "text"
      },
      "source": [
        "### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGxLHevsfN0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = tf.reshape(y_pred, [-1,192,256])\n",
        "true = tf.reshape(y_true, [-1,192,256])\n",
        "          \n",
        "\n",
        "intersect = tf.reduce_sum(tf.cast(true*pred, tf.float32), axis = [1,2])\n",
        "sum_pred = tf.reduce_sum(tf.cast(pred*pred, tf.float32), axis = [1,2])\n",
        "sum_true = tf.reduce_sum(tf.cast(true*true, tf.float32), axis = [1,2])\n",
        "union = sum_pred + sum_true - intersect  \n",
        "jacc = intersect/union\n",
        "            \n",
        "\n",
        "\n",
        "#cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7_7P_MxxKvn",
        "colab_type": "text"
      },
      "source": [
        "This will be updated to a loss function based on the jaccard index, as in the related publication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd8V8rTafN0l",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShpM5aWifN0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.003)\n",
        "#cost = -tf.reduce_mean(tf.nn.sigmoid(jacc))\n",
        "cost =  tf.reduce_mean(tf.nn.relu(0.78 - jacc))\n",
        "train = optimizer.minimize(cost)   #can this be done for each pixel?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pgeA03VfN0o",
        "colab_type": "text"
      },
      "source": [
        "### Intialize Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6p_q-h8fN0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJBnGN8bfN0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJSc-_gtfN0s",
        "colab_type": "text"
      },
      "source": [
        "Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCgyHGU9fN0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mel = MelHelper()\n",
        "mel.set_up_images()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TquTnDl1vKyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.math.exp(1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LvFchSc7fN0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps = 10500\n",
        "import time\n",
        "batch_size = 16\n",
        "j_test = []\n",
        "j_train = []\n",
        "\n",
        "#use Cifar_helper to set up next batch\n",
        "with tf.Session() as sess:\n",
        "    print(\"starting init\")\n",
        "    sess.run(init)\n",
        "    print(\"done init\")\n",
        "    \n",
        "    start_time = time.clock()\n",
        "    \n",
        "    for i in range(steps): \n",
        "        batch_x, batch_y = mel.next_batch(batch_size)\n",
        "        #print(i)\n",
        "        #print(\"\\n\")\n",
        "        \n",
        "        #print(\"batch training labels shape is \", batch_y.shape)\n",
        "        #print(\"batch training labels type is \", batch_y.dtype)\n",
        "        #print(\"batch training labels are \", batch_y)\n",
        "        #print(\"batch training data are \", batch_x)\n",
        "        #image = batch_y.reshape(-1,21,28)[5,:,:]\n",
        "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5,hold_prob2:0.5})\n",
        "        #print(\"batch training prediction are \", batch_y)\n",
        "        #image_pred = sess.run(y_pred,feed_dict={x:batch_x,y_true:batch_y,hold_prob:1.0} ).reshape(-1,21,28)[5,:,:]\n",
        "        #image_pred = np.round(1/(1 + np.exp(-image_pred)))\n",
        "        \n",
        "        if i%100 == 0:\n",
        "            print('Currently on step {}'.format(i))\n",
        "            print(\"the time is \", time.clock() - start_time, \"\\n\")\n",
        "             #print(\"mel i is \", mel.i)\n",
        "             #plt.imshow(image)\n",
        "             #plt.show()\n",
        "             #plt.imshow(image_pred)\n",
        "             #plt.show()\n",
        "            \n",
        "            #print('Currently on step {}'.format(i))\n",
        "            #print('Accuracy is:')\n",
        "            # Test the Train Model\n",
        "            #matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "\n",
        "            #acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "            \n",
        "            ####use with cross entropy####\n",
        "            #pred = tf.round(1/(1 + tf.exp(-tf.reshape(y_pred, [-1,48,64]))))\n",
        "            #true = tf.reshape(y_true, [-1,48,64])\n",
        "          \n",
        "            # Test the Train Model\n",
        "            #matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))  ###REPLACE THIS LINE TO INCLUDE JACARD INDEX####\n",
        "            pred_o = tf.math.round(pred)\n",
        "            true_o = tf.math.round(true)\n",
        "            \n",
        "        \n",
        "\n",
        "\n",
        "            intersect_o = tf.reduce_sum(tf.cast(true*pred_o, tf.float32), axis = [1,2])\n",
        "            union_o = tf.reduce_sum(tf.cast(pred_o, tf.float32), axis = [1,2]) + tf.reduce_sum(tf.cast(true, tf.float32), axis = [1,2]) - intersect_o  #think this has an error\n",
        "            jacc_o = intersect_o/union_o\n",
        "            \n",
        "            \n",
        "            J_out_t = sess.run([jacc_o],feed_dict={x:batch_x,y_true:batch_y,hold_prob:1.0,hold_prob2:1.0})\n",
        "            J_train = np.sum(J_out_t[0])/J_out_t[0].shape[0]\n",
        "            j_train += [J_train]\n",
        "            \n",
        "            #acc = tf.reduce_mean(tf.cast(intersect,tf.float32))\n",
        "            #print(\"test labels shape is \", mel.test_labels.shape)\n",
        "            #print(\"\\n\")\n",
        "            \n",
        "            print('Avg Jacc is:')\n",
        "            J_out = sess.run([jacc_o, pred_o, true_o],feed_dict={x:mel.test_images,y_true:mel.test_labels,hold_prob:1.0, hold_prob2:1.0})\n",
        "           \n",
        "           \n",
        "            rn = int(np.random.random()*J_out[1].shape[0])\n",
        "           \n",
        "            plt.imshow(J_out[1][rn, :, :])\n",
        "            plt.show()\n",
        "            plt.imshow(J_out[2][rn, :, :])\n",
        "            plt.show()\n",
        "            ##it cannot evaluate over the test set, the test set is too large...reduce size of test set\n",
        "            \n",
        "            J_test = np.sum(J_out[0])/J_out[0].shape[0]\n",
        "            j_test += [J_test]\n",
        "            \n",
        "            print(J_test, \" step number is \",  i, \" batch_size is \", batch_size)\n",
        "            #print(\"intersection is\", J_out[2], \"union is\", J_out[3], \"\\n\", \"y_pred is \", J_out[4], \"true is \", J_out[5], \"sum_pred =\",  J_out[6], \"sum_true\", J_out[7])\n",
        "            #if i == 500:\n",
        "                #batch_size = 20\n",
        "            #if i == 25000:\n",
        "                #batch_size = 200\n",
        "            \n",
        "            #print out Jacc for training set and test set, Save Jacc and entropy to variable,\n",
        "            #print out step number\n",
        "            \n",
        "            #use larger pics\n",
        "            #print out and analyse cross entropy\n",
        "            #run with full training batch for several iterations\n",
        "            #pred = sess.run(pred,feed_dict={x:mel.test_images,y_true:mel.test_labels,hold_prob:1.0})\n",
        "            \n",
        "           \n",
        "        if i == steps - 1:\n",
        "            pred_mel = sess.run([pred],feed_dict={x:mel.test_images,y_true:mel.test_labels,hold_prob:1.0, hold_prob2:1.0})\n",
        "            pred_pigment = sess.run([pred],feed_dict={x:pigs,hold_prob:1.0,hold_prob2:1.0})\n",
        "            \n",
        "        #save_path = saver.save(sess, \"./model.ckpt\")\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgBtoXllqHTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "J_out[1].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuEdKJQ85Nqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j_train = np.array(j_train)\n",
        "j_test = np.array(j_test)\n",
        "plt.plot(j_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6h0-RmJcPJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.plot(j_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hy80bHP4M37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(J_out[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lvmxblpnxO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(J_out_t[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9grxJSCowWDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#failure rate on test set:\n",
        "fails = 0\n",
        "for a in J_out[0]:\n",
        "  if a < 0.65:\n",
        "    fails += 1\n",
        "    \n",
        "rate = fails/J_out[0].shape[0]\n",
        "rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozKxJoKafN0x",
        "colab_type": "text"
      },
      "source": [
        "## Great Job!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPBW3tGrfN0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(pred_pigment[0][5,:,:])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F065GTgDfN0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigs.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpT_cK9NfN01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_pigment[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyGWGE_HmlWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxfv9B0wfN03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(pigment_image_show)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAPOpkOnfN05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visual_progress():\n",
        "\n",
        "  mask = np.zeros([192,256,3])#np.vstack([pred_pigment[0],pred_pigment[0],pred_pigment[0]])\n",
        "  for i in range(28):\n",
        "    mask[:,:,0] = np.around(pred_pigment[0][i])\n",
        "    mask[:,:,1] = np.around(pred_pigment[0][i])\n",
        "    mask[:,:,2] = np.around(pred_pigment[0][i])\n",
        "\n",
        "\n",
        "    image = pigs[i]\n",
        "    notmask = 1- mask\n",
        "    image2 = image*mask\n",
        "    image1 = image*(1- mask)\n",
        "\n",
        "    image2_avgr = np.average(image2[:,:,0], weights = mask[:,:,0])\n",
        "    image2_avgg = np.average(image2[:,:,1], weights = mask[:,:,1]) \n",
        "    image2_avgb = np.average(image2[:,:,2], weights = mask[:,:,2])\n",
        "\n",
        "    image1_avgr = np.average(image1[:,:,0], weights = notmask[:,:,0])\n",
        "    image1_avgg = np.average(image1[:,:,1], weights = notmask[:,:,1]) \n",
        "    image1_avgb = np.average(image1[:,:,2], weights = notmask[:,:,2])\n",
        "\n",
        "    image2_avg = np.zeros(image2.shape)\n",
        "    image1_avg = np.zeros(image1.shape)\n",
        "    image2_avg[:,:,0] = image2_avgr\n",
        "    image2_avg[:,:,1] = image2_avgg\n",
        "    image2_avg[:,:,2] = image2_avgb\n",
        "\n",
        "    image1_avg[:,:,0] = image1_avgr\n",
        "    image1_avg[:,:,1] = image1_avgg\n",
        "    image1_avg[:,:,2] = image1_avgb\n",
        "#mask = 1-mask\n",
        "#mask = mask.astype(int)\n",
        "    plt.imshow(image2_avg)\n",
        "    plt.show()\n",
        "  \n",
        "#image[mask] = 0\n",
        "\n",
        "    plt.imshow(image1_avg)\n",
        "    plt.show()\n",
        "\n",
        "    plt.imshow(image2)\n",
        "    plt.show()\n",
        "    plt.imshow(image1)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"next day..\\n\")\n",
        "  return()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xirh3WruWeIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visual_progress()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5dc6TdTfN1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def measure_progress(pigs,masks):  ##changed from blue to blue - red\n",
        "    blue_pigs = []\n",
        "    blue_norms = []\n",
        "    imagesp = []\n",
        "    imagesn = []\n",
        "    i = 0\n",
        "    for pig in pigs:\n",
        "        mask = np.zeros([192,256,3])#np.vstack([pred_pigment[0],pred_pigment[0],pred_pigment[0]])\n",
        "        mask[:,:,0] = pred_pigment[0][i,:,:]\n",
        "        mask[:,:,1] = pred_pigment[0][i,:,:]\n",
        "        mask[:,:,2] = pred_pigment[0][i,:,:]\n",
        "        mask_inv = 1- mask\n",
        "        imagep = pig*mask*255\n",
        "        imagen = pig*(1- mask)*255\n",
        "        imagesp += [imagep]\n",
        "        imagesn += [imagen]\n",
        "        blue_norm = imagen[:,:,2].reshape(-1) - imagen[:,:,0].reshape(-1) \n",
        "        blue_pig = imagep[:,:,2].reshape(-1) - imagep[:,:,0].reshape(-1)\n",
        "        an = np.average(blue_norm, weights =mask_inv[:,:,0].reshape(-1))\n",
        "        ap = np.average(blue_pig, weights =mask[:,:,0].reshape(-1))\n",
        "        blue_pigs += [ap]\n",
        "        blue_norms += [an]\n",
        "        i+=1\n",
        "    blue_pigs = np.array(blue_pigs)\n",
        "    blue_norms = np.array(blue_norms)\n",
        "    return(blue_pigs, blue_norms, imagesp, imagesn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gl1CurMfN1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigmented, normal, imagesp, imagesn = measure_progress(pigs,pred_pigment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIybHR8HfN1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "J_out[1].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFU1gqlwfN1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigmented"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGl5P8_DfN1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI0Ug5XQfN1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(normal - pigmented)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y-HM_QTfN1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPauIGdCfN1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(pigmented)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKYExBeMfN1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGbveiABfN1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLx2lHwtfN1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5_39MM-fN1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3d7xIRpfN1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVuabyyffN1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecXz5Qg2fN1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vljOjV8AfN1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20qm-GS0fN1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[8])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_raVEmR1fN1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLG0X9zwfN1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "551fWebzfN1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigmented[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD9EF_yxfN1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigmented[10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks9ZDXfWfN1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqMFsSngfN1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[11])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHHB-0G2fN1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[12])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgSGsY2YfN1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[13])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4TjKPuQfN1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[14])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yDzxusDfN1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[15])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px8uG7stfN1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[16])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCVqCLpcfN1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[17])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UXuk8sxfN1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[18])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbx4K_-9fN1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[19])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6MwZhmyfN1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2t3dY8EfN11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[21])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuGQCCKnfN11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[22])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ust1UM-LfN15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[23])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrAjXfnUfN16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[24])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nig__U98fN16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[25])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7tRlK70fN17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[26])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhAjKp-FfN18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[27])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONZHGxYgfN19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBoXOjU6fN1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = normal - pigmented"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3vR3FEkfN1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = np.hstack([test[0:2], test[4:8], test[9:21], test[22:26], test[27]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBWPYJQqfN2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUhETHmvfN2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXZzpi6CfN2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal = np.hstack([normal[0:2], normal[12], normal[21:28], normal[2:12], normal[13:20]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCGAAJMafN2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigmented = np.hstack([pigmented[0:2], pigmented[12], pigmented[21:28], pigmented[2:12], pigmented[13:20]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oUhRhYvfN2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(normal-pigmented)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQzHMxI8fN2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 26, 21, 2, 3, 8 -> 8,3,10,11,16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSo5OEV8fN2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuY1yTNrfN2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal = np.hstack([normal[0:3], normal[4:8], normal[9], normal[12:16], normal[17:27]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR9K3H7ufN2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pigmented = np.hstack([pigmented[0:3], pigmented[4:8], pigmented[9], pigmented[12:16], pigmented[17:27]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xtRhAlQfN2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_files_names = np.hstack([filenames[0:3], filenames[4:8], filenames[9], filenames[12:16], filenames[17:27]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bn2MCC6fN2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(normal-pigmented)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGsF6DPXfN2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(pigmented)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edq64hVRfN2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKzE4nHQfN2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(pigmented/normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlBabwzifN2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot((normal - pigmented)/normal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgYrZGrXfN2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_files_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTrCVmMOfN2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(imagesp[12])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtyHpfeIfN2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-fgJ663fN2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT9oUH6HujIw",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}